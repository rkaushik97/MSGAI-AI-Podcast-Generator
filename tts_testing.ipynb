{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio as Audio_rep, display\n",
    "import logging, warnings\n",
    "from transformers import logging as hf_logging\n",
    "from huggingface_hub import login\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset, load_from_disk, Audio\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setting up HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1763453269296,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "tdUdwKrt_TH1"
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Hugging face login\n",
    "#######################################################\n",
    "# Silence transformers/TRL logs early\n",
    "hf_logging.set_verbosity_error()\n",
    "logging.getLogger(\"trl\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hide specific noisy warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\".*loss_type=None.*ForCausalLMLoss.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\".*cuDNN SDPA backward got grad_output\\.strides\\(\\) != output\\.strides\\(\\).*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "os.environ[\"TQDM_NOTEBOOK\"] = \"0\"\n",
    "\n",
    "#############################################\n",
    "########## Google Colab #####################\n",
    "# setting key in secrets google colab\n",
    "# from google.colab import userdata\n",
    "# hf_key = userdata.get('HUGGINGFACE_API_KEY')\n",
    "#############################################\n",
    "########## Locally with env file ############\n",
    "# Load .env file (if present)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "hf_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "#############################################\n",
    "\n",
    "if hf_key:\n",
    "    login(hf_key)\n",
    "else:\n",
    "    raise EnvironmentError(\"HUGGINGFACE_API_KEY not found. Copy .env.template to .env and add your token. See Instruction.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Dataset - LJ Speech Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either download the dataset from Kaggle or Huggingface, 13100 short audio clips, with transcription, from Kaggle \n",
    "you get individual .wav files.\n",
    "\n",
    "The size of the dataset is 3GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"mathurinache/the-lj-speech-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Create in the root of the project a /datasets folder and move the donwloaded dataset there,\n",
    "# otherwise set use the default path where it has been saved (usually .cache/kagglehub)\n",
    "DATASET_PATH = 'mathurinache/the-lj-speech-dataset/versions/1/LJSpeech-1.1'\n",
    "DATASET_NAME = 'LJSpeech1_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "df = pd.read_csv(\n",
    "    f\"./datasets/{DATASET_PATH}/metadata.csv\",\n",
    "    sep=\"|\",\n",
    "    names=[\"id\", \"text\", \"normalized\"],\n",
    ")\n",
    "\n",
    "# Add full audio paths\n",
    "df[\"audio\"] = df[\"id\"].apply(\n",
    "    lambda x: f\"./datasets/{DATASET_PATH}/wavs/{x}.wav\"\n",
    ")\n",
    "\n",
    "# Rename fields to match your benchmark code\n",
    "df = df.rename(columns={\"text\": \"spoken_text\"})\n",
    "\n",
    "# Create HuggingFace dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tell HF that \"audio\" contains audio files\n",
    "dataset = dataset.cast_column(\"audio\", \n",
    "    load_dataset(\"audiofolder\", data_dir=f\"./datasets/{DATASET_PATH}/wavs\")[\"train\"].features[\"audio\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"MikhailT/lj-speech\"\n",
    "# load dataset\n",
    "import datasets\n",
    "\n",
    "dataset_local = True\n",
    "if dataset_local:\n",
    "    dataset = load_from_disk(os.path.join('datasets', DATASET_NAME))\n",
    "else:\n",
    "    dataset = load_dataset(DATASET_NAME, split=\"full\", streaming=False).select(range(NUM_SAMPLES))\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", datasets.features.Audio(decode=False))\n",
    "\n",
    "# save dataset locally    \n",
    "# dataset.save_to_disk(f'./datasets/{DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Models Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1763453269344,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "QNvJ_Tm18K5L"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# CONFIGURATION\n",
    "#######################################################\n",
    "from pathlib import Path\n",
    "\n",
    "# Set your models here\n",
    "TTS_MODELS = [\n",
    "    # \"bark_small\", # \"suno/bark-small\",\n",
    "    \"speecht5_tts\", # \"microsoft/speecht5_tts\"                          \n",
    "    \"mms_tts\"\n",
    "]\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Directory to store generated audio\n",
    "OUTPUT_DIR = Path(\"tts_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOREkPHZ3UWt"
   },
   "source": [
    "---\n",
    "### Microsoft/speecht5_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "\n",
    "speecht5_tts_local_path = './models/speecht5_tts'\n",
    "speecht5_tts_local = True\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    processor = SpeechT5Processor.from_pretrained(speecht5_tts_local_path if speecht5_tts_local else \"microsoft/speecht5_tts\")\n",
    "    model = SpeechT5ForTextToSpeech.from_pretrained(speecht5_tts_local_path if speecht5_tts_local else \"microsoft/speecht5_tts\")\n",
    "    vocoder = SpeechT5HifiGan.from_pretrained(os.path.join(speecht5_tts_local_path, \"vocoder\") if speecht5_tts_local else \"microsoft/speecht5_hifigan\")\n",
    "except OSError:\n",
    "    raise EnvironmentError(\"Make sure that the local path to the model is correct.\")\n",
    "else:\n",
    "    models[\"speecht5_tts\"] = {\"processor\": processor, \"model\": model, \"vocoder\": vocoder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model locally\n",
    "# save_path = \"./models/speecht5_tts\"\n",
    "# models[\"speecht5_tts\"]['model'].save_pretrained(save_path)\n",
    "# models[\"speecht5_tts\"]['processor'].save_pretrained(save_path)\n",
    "# models[\"speecht5_tts\"]['vocoder'].save_pretrained(os.path.join(save_path, 'vocoder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "295f595683e84d34bc3763d31ff87a95",
      "2bb5d1ce96ec44719041f735f597a13c",
      "24660d31fd464d70a511a30bed0d5053",
      "bf998b2be0b44c26a9ec3d14d1e3d177",
      "2a4ba0ec7f6c4d0a8062cdfed5a85622",
      "18c42653e32544a283d73e2099a8b34d",
      "92ee9ed2b9ac4afd9fc79ada0c254c9f",
      "30805482adbf47c3a3fb949f52fe6031",
      "130e20c90e7048eb8519d87bec699de4",
      "01ce262239d54eb288dba669bd54e330",
      "225e293e337a4bb884cd05c3f940584a",
      "ba214e65af624e5680c050181c3d5b98",
      "54f5492abdec48a3a6784afdd35430dd",
      "2d68c40c3a2045eb84e2b6a78a5e7b57",
      "7a27f755e91a49d9a6dfbfc64e54a7ec",
      "4509e690d13f462ebaf7deb263ea1162",
      "f09825a20ae540ec96217b7a5e4e0958",
      "8d5a951ab70c46fdba4cf9b7889c2449",
      "25407e7505c647688e6f3c267c7d2c53",
      "aa0f111e94f3405dba55676472631fc7",
      "b52f92832c034d3390412d529c419b06",
      "9c965f96d84f48ee804e3a6d207fd494",
      "eb4f8657d0074a068f29a944e214eda3",
      "c864deb298f14b279040a0d96b03262c",
      "20f29176438243edb2a6830d37671bef",
      "372d95744609478385b9d2af1dbe7782",
      "cc195d523f9249159d519bb79d0543f4",
      "3f60317574ab489c90a083d20b9a0252",
      "932941e88181402abfc24e6f269ffc93",
      "6bd58e48af50403296304ab9dad8d7da",
      "124975e795e3467d85ba80a65069d57b",
      "46a60099f2c24547aa8f5051d073af86",
      "663e1b727bd54d24808fcd3090b577a9",
      "78000bd8b7eb494ea54038962c99d8dc",
      "7b19108a746942b4ac1530592dff40f9",
      "cae48c01d2cd4ad7958eb512ddad1d0e",
      "da73b8df8368495499ef93560cbdf2a3",
      "9d9e136fe6f14a8b8abf897736940ad5",
      "a7fafbc469604c2ab0710131980f43af",
      "0c4f0abfccea4e65b73fa038291e831c",
      "2c7d4d07089c4cf5808c32e9a7d8d1fe",
      "2b9737d8a3fc47f1abd30b17c50a33cf",
      "c803074d7cde4ff2a819d3a6237b176d",
      "53c4805bcec64bbc8fd3bd981098a9dd",
      "350288b04eac4cb2aba8e005aca59ad0",
      "33a165ddecf14faab7b904ec25bd548e",
      "137ab4d0dff44c489d7435fc6329d10b",
      "997dd796646542e4a4e2f7575ad8f23f",
      "d01b06c5c1604e43973bd161ed68da3d",
      "264c0b0ded2442c8b32dea7fdef52d5f",
      "9a927a7b0e3f4081aa70a4b5199a85fe",
      "be0c3db9697c49edbaebb73ce53cc69e",
      "8915e22fef9445fe90b01fc9c83e0623",
      "4e2b5d2e2e21462f94ad50c4f8cc2b2c",
      "2f34c9ed8822442eb2ac032c6d3408fc",
      "4c25ea0fec4a48b6bc852f9f34805e3b",
      "6f606ac009d847bdbd3b615adf824cca",
      "3c6e40586abf4a378bdb0b92fd84f97c",
      "873dee0cc5054837bccb59afb0ca0996",
      "294410be56ef48b89c590717afd1752f",
      "a8d7df5445c24cc1a70dbcb7c853e062",
      "ea196e49a96444208bbb35163e587f4b",
      "af26b3fe5573478fbca9bf31d2c102f4",
      "e27eeff95e984b10b88e6b4401d01fee",
      "cda6873c816b4a02b5ef2a354730ce82",
      "3ec48efe8710456b95f61ed2a449bc74",
      "523254a696ed455793ea137f722e0b2b",
      "ce64743517c24372896bda307df067c4",
      "2902d81f43674e67a363e99e7c9a4b9a",
      "5922e077f65b47cdb7cb3c581cef6990",
      "23cd8a8a762849b18a2da1bb295f6a87",
      "305afd41d81b415ab69c9895655f0de7",
      "a906bc7bbeff4a53b24067c120269dc0",
      "d0ff229f3b61456cb82f94317ae49ea8",
      "492895dafe0243b4b38060a4e5f3a057",
      "fe1eb1fd2dc340aea64625849611320b",
      "1f0206adb7374f4d9efb6bc1ffb56185",
      "6671e81283794420b2d9e97f719c5c7e",
      "69ed15a9b4c9466b87535d54c45bcf03",
      "028bdb54db4c426d9fd3e67600d39bea",
      "a9abface27ad412bbad4654dbc66963c",
      "1a2373ef58f04b4ea15465bb686cc706",
      "f5d08be1c20c49b2ab98afb14a2d2dc9",
      "2727528989b743108ca2505fd708d8fa",
      "7f0a98fae56741b6896fbe2b414f9548",
      "2507e3d1bcb24770b731151f39a2aa30",
      "d96df5231e5f4734a1240a57c4fe2574",
      "c656acf25e2c40cd862b40f7408dfc36",
      "a1881bbed3a24252a73dbc540563c366",
      "d418e58d1b1d48b8a60a179d6c2675d9",
      "04d0231dedf34b639ee6ba68833819dd",
      "d243bb0dc6fa4a469ffd664b7c3166f1",
      "0049942822804802ae0758ab039d5dfb",
      "fc9f781429784c4191a8330cde3b13d6",
      "2e3f67d8e81e41a6bee1f33965de7e71",
      "f296225bffe74f609fa2da6e2eb9c8ef",
      "64eb9093f7464a8b8962055589202a72",
      "9de1664387d04472a44c2ec359ee6ad2",
      "69eee7e6b4ce4dfd8a5835c3e4272a82",
      "8d27ffa7571f416e998921517cd9ed24",
      "dcb47c7337a0412b91b55aaf553c28de",
      "e7b6be45050d46f3beba7fdad78418ee",
      "8da524ab48614c08a1f45ff0fa981bab",
      "c00421509a444d3aa438b9258314ec38",
      "c85428bbea6f4cd99bf8d4d6d3fabfc0",
      "27bd50808866461aa5ed4da2197ebf0b",
      "0d46dffc12514bae92dd992ca26f99d3",
      "bcb7338c17ba43dc9d1b5531f40411c9",
      "7d1dc0e7e7f54b89af00da117dd42bb0",
      "13bfcf8074f045b6ac4e9e55ca155fe6",
      "15fabcf9607d4a0dbe62322db6e2a68d",
      "a7337f6435be407c895b3720219781aa",
      "497bc9eb9d7042e8832885d072c0c358",
      "87a876686a954ab883c11c9755543d6e",
      "180a02582db74d06b9ff27c4cf191de0",
      "4a01b6e92bdb40b7a37f5c388f77d7b7",
      "258a417c8fb74e819ce1102cc57c0b55",
      "777dbd3efdde4c4488058ad0e526afe4",
      "599b23c960e641c5b0d111b93762e8fe",
      "db39125877e4464384ca9f49b6053a68",
      "51d299e9ec1840e9bb2e6d7055bff1ac"
     ]
    },
    "executionInfo": {
     "elapsed": 17366,
     "status": "ok",
     "timestamp": 1763453605608,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "PfZg5aq23cZw",
    "outputId": "dd36c897-c019-4e1c-ed01-69cebf1e6fae"
   },
   "outputs": [],
   "source": [
    "# Prepare input text\n",
    "inputs = models['speecht5_tts']['processor'](text=\"Test one, two, three, I am talking!\", return_tensors=\"pt\")\n",
    "\n",
    "# Use a random speaker embedding (512 dimensions)\n",
    "speaker_embeddings = torch.randn(1, 512)\n",
    "\n",
    "# Generate speech\n",
    "with torch.no_grad():\n",
    "    speech = models['speecht5_tts']['model'].generate_speech(\n",
    "        inputs[\"input_ids\"],\n",
    "        speaker_embeddings,\n",
    "        vocoder=models['speecht5_tts']['vocoder']\n",
    "    )\n",
    "\n",
    "# Save output\n",
    "sf.write(f\"{OUTPUT_DIR}/speecht5_tts/speech_test.wav\", speech.numpy(), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1763453656286,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "dqDlJAG14PcF",
    "outputId": "a2871380-5a6d-4d3e-c720-ef1d587d00c3"
   },
   "outputs": [],
   "source": [
    "display(Audio_rep(f\"{OUTPUT_DIR}/speecht5_tts/speech_test.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### facebook/mms-tts-eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VitsModel, AutoTokenizer\n",
    "\n",
    "mms_tts_local_path = './models/mms_tts'\n",
    "mms_tts_local = False\n",
    "# Load models\n",
    "try:\n",
    "    model = VitsModel.from_pretrained(mms_tts_local_path if mms_tts_local else \"facebook/mms-tts-eng\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(mms_tts_local_path if mms_tts_local else \"facebook/mms-tts-eng\")\n",
    "except OSError:\n",
    "    raise EnvironmentError(\"Make sure that the local path to the model is correct.\")\n",
    "else:\n",
    "    models[\"mms_tts\"] = {\"model\": model, \"tokenizer\": tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model locally\n",
    "# save_path = \"./models/mms_tts\"\n",
    "# models[\"mms_tts\"]['model'].save_pretrained(save_path)\n",
    "# models[\"mms_tts\"]['tokenizer'].save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Test one, two, three, I am talking!\"\n",
    "inputs = models['mms_tts']['tokenizer'](text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = models['mms_tts']['model'](**inputs).waveform\n",
    "\n",
    "sf.write(f\"{OUTPUT_DIR}/mms_tts/speech_test.wav\", output.cpu().numpy().squeeze(), models['mms_tts']['model'].config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio_rep(f\"{OUTPUT_DIR}/mms_tts/speech_test.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1763453921423,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "kPHhfnxg_f5b"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# METRICS — Small, simple (expand as needed)\n",
    "#######################################################\n",
    "import soundfile as sf\n",
    "\n",
    "def audio_duration(path):\n",
    "    \"\"\"Returns duration in seconds.\"\"\"\n",
    "    y, sr = librosa.load(path, sr=None)\n",
    "    return len(y) / sr\n",
    "\n",
    "def infer_model(models, model_name, texts):\n",
    "    if model_name == 'speecht5_tts':\n",
    "        if len(texts) > 1:\n",
    "            print(\"Speecht5_tts cannot be ran with batches, only the first text will be passed to the model\")\n",
    "            \n",
    "        inputs = models[model_name]['processor'](text=texts[0], return_tensors=\"pt\")\n",
    "        # Use a random speaker embedding (512 dimensions)\n",
    "        # speaker_embeddings = torch.randn(1, 512)\n",
    "        # fix voice for the moment\n",
    "        speaker_embeddings = torch.zeros(1, 512)\n",
    "\n",
    "        # Generate speech\n",
    "        with torch.no_grad():\n",
    "            generated = models[model_name]['model'].generate_speech(\n",
    "                inputs[\"input_ids\"],\n",
    "                speaker_embeddings,\n",
    "                vocoder=models[model_name]['vocoder']\n",
    "            )\n",
    "        \n",
    "        return [generated]\n",
    "        \n",
    "    elif model_name == 'mms_tts':\n",
    "        inputs = models[model_name]['tokenizer'](text=texts, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "          generated = models[model_name]['model'](**inputs).waveform\n",
    "        \n",
    "        return generated\n",
    "\n",
    "    else:\n",
    "        Warning(\"Model not implemented yet!\")\n",
    "        return None\n",
    "\n",
    "def save_gen_audio(model_name, output_audio_path, audio, sample):\n",
    "    if model_name == 'speecht5_tts':\n",
    "        # output_audio_path = model_dir / f\"sample_{b_start}_bs{batch_size}.wav\"\n",
    "        sf.write(output_audio_path, audio.numpy(), 16000)\n",
    "        # Metrics\n",
    "        duration = audio_duration(output_audio_path)\n",
    "        # similarity = mel_spectrogram_similarity(reference_audio_path,output_audio_path)\n",
    "    elif model_name == 'mms_tts':\n",
    "        waveform = audio.cpu().numpy()\n",
    "        sf.write(output_audio_path, waveform, models[model_name]['model'].config.sampling_rate)\n",
    "        # Metrics\n",
    "        duration = audio_duration(output_audio_path)\n",
    "        # similarity = mel_spectrogram_similarity(reference_audio_path,output_audio_path)\n",
    "\n",
    "    return {\n",
    "        \"text\": sample[\"spoken_text\"],\n",
    "        \"reference\": sample[\"audio\"][\"path\"],\n",
    "        \"generated\": str(output_audio_path),\n",
    "        \"duration\": duration\n",
    "        # \"mel_similarity\": float(similarity)\n",
    "    }\n",
    "\n",
    "# def mel_spectrogram_similarity(ref_path, gen_path):\n",
    "#     \"\"\"\n",
    "#     Simple similarity metric comparing mel spectrogram cosine similarity.\n",
    "#     Not perfect, but useful for midterm presentation.\n",
    "#     \"\"\"\n",
    "#     ref, sr_ref = librosa.load(ref_path, sr=22050)\n",
    "#     gen, sr_gen = librosa.load(gen_path, sr=22050)\n",
    "\n",
    "#     ref_mel = librosa.feature.melspectrogram(ref, sr=22050)\n",
    "#     gen_mel = librosa.feature.melspectrogram(gen, sr=22050)\n",
    "\n",
    "#     ref_vec = np.mean(ref_mel, axis=1)\n",
    "#     gen_vec = np.mean(gen_mel, axis=1)\n",
    "\n",
    "#     return 1 - cosine(ref_vec, gen_vec)\n",
    "    \n",
    "\n",
    "#######################################################\n",
    "# Run the benchmark on a given dataset\n",
    "#######################################################\n",
    "def run_tts_benchmark(dataset, exp_folder):\n",
    "\n",
    "    for model_name in TTS_MODELS:\n",
    "        print(f\"\\n### Running inference for: {model_name}\")\n",
    "        model_dir = OUTPUT_DIR / model_name.replace(\"/\", \"_\") / exp_folder\n",
    "        model_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Warmup the model\n",
    "        warmup_text = \"Warm up the model.\"\n",
    "        print(\"Running warm-up…\")\n",
    "        _ = infer_model(models, model_name, [warmup_text])\n",
    "        print(\"Warm-up complete.\\n\")\n",
    "        \n",
    "        for batch_size in BATCH_SIZES:\n",
    "          print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "          model_results = []\n",
    "          samples = list(dataset)\n",
    "\n",
    "          if (model_name == 'speecht5_tts' and batch_size != 1):\n",
    "             print('speecht5_tts does not support batching, skip...')\n",
    "             continue\n",
    "\n",
    "          for b_start in tqdm(range(0, len(samples), batch_size)):\n",
    "              batch = samples[b_start:b_start+batch_size]\n",
    "              texts = [s[\"spoken_text\"] for s in batch]\n",
    "\n",
    "              # ----- Inference -----\n",
    "              t0 = time.time()\n",
    "\n",
    "              generated_batch = infer_model(models, model_name, texts)\n",
    "\n",
    "              if generated_batch is None:\n",
    "                  print(\"Something went wrong while generating the batch!\")\n",
    "                  return\n",
    "\n",
    "              t1 = time.time()\n",
    "\n",
    "              ## save generated audio and results\n",
    "              for idx, (sample, audio) in enumerate(zip(batch, generated_batch)):\n",
    "                output_audio_path = model_dir / f\"sample_{b_start + idx}_bs{batch_size}.wav\"\n",
    "                results = save_gen_audio(model_name, output_audio_path, audio, sample)\n",
    "                results['batch_size'] = batch_size\n",
    "                results['inference_time'] = t1 - t0\n",
    "                model_results.append(results)\n",
    "\n",
    "          # Save model results\n",
    "          with open(model_dir / f\"results_bs{batch_size}.json\", \"w\") as f:\n",
    "              json.dump(model_results, f, indent=2)\n",
    "              \n",
    "    print(\"\\nDone! Benchmarking done, save results in\", OUTPUT_DIR, \" and inside the model folder, under \", exp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [1, 5]\n",
    "NUM_SAMPLES = 2   # subset for fast evaluation\n",
    "exp_folder = 'test0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1tux8_EjCyn4hv5bt7zQEZJALDrhvCERA"
    },
    "executionInfo": {
     "elapsed": 261255,
     "status": "ok",
     "timestamp": 1763454183530,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "hFcTgUMH8zZx",
    "outputId": "4a1fbe4e-9d63-40f9-cb42-90d4c3ab2ef0"
   },
   "outputs": [],
   "source": [
    "dataset_sampled = dataset.select(range(NUM_SAMPLES))\n",
    "run_tts_benchmark(dataset_sampled, exp_folder)\n",
    "print(TTS_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763454441239,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "3DCxkJ18AyYr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exp_to_import = 'test0'\n",
    "df_mms_tts_b1 = pd.read_json(f'tts_results/mms_tts/{exp_to_import}/results_bs1.json')\n",
    "df_mms_tts_b5 = pd.read_json(f'tts_results/mms_tts/{exp_to_import}/results_bs5.json')\n",
    "df_speecht5_tts_b1 = pd.read_json(f'tts_results/speecht5_tts/{exp_to_import}/results_bs1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1763454463286,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "qXX-MnuKE4Ir",
    "outputId": "8f5737a9-14b7-44a1-a5be-4a621f273181"
   },
   "outputs": [],
   "source": [
    "df_mms_tts_b1.head(5)\n",
    "df_mms_tts_b1['rtf'] = df_mms_tts_b1['duration']/df_mms_tts_b1['inference_time']\n",
    "df_mms_tts_b1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mms_tts_b5.head(5)\n",
    "df_mms_tts_b5['rtf'] = 5*df_mms_tts_b5['duration']/df_mms_tts_b5['inference_time']\n",
    "df_mms_tts_b5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speecht5_tts_b1.head(5)\n",
    "df_speecht5_tts_b1['rtf'] = df_speecht5_tts_b1['duration']/df_speecht5_tts_b1['inference_time']\n",
    "df_speecht5_tts_b1.describe()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMIP/Y1hL+PXS5z+9n/PgnW",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
