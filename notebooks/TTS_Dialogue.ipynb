{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9803d88-7d5c-4095-a380-4c0eb52a2b2e",
   "metadata": {},
   "source": [
    "# TTS HQ model on Podcast scripts\n",
    "### Author: Kaushik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50a8500-5861-4750-bbc3-5021d846eb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'topic': 'The Simulation Theory: Are we living in a video game?',\n",
       " 'host_gender': 'MALE',\n",
       " 'guest_gender': 'MALE',\n",
       " 'guest_name': 'Dr. Elliot Thompson',\n",
       " 'dialogue': 'HOST: Welcome to the Adaptive AI Podcast, where we explore the intersection of technology and human experience. I\\'m your host, Alex Chen.\\nHOST: Today, we\\'re diving into one of the most mind-bending ideas in modern philosophy: the Simulation Theory. Are we living in a video game created by a more advanced civilization?\\nHOST: Joining me is Dr. Elliot Thompson, a renowned philosopher and expert on the Simulation Theory. Dr. Thompson, welcome to the show.\\nGUEST: Thanks for having me, Alex.\\nHOST: So, let\\'s get started. What\\'s the basic idea behind the Simulation Theory?\\nGUEST: The Simulation Theory proposes that our reality is a simulation created by a more advanced civilization, often referred to as the \"simulators.\" This idea is based on the notion that a civilization with sufficient advanced technology could create a realistic simulation of reality, and that we might be living in such a simulation. Some arguments in favor of this theory include the rapid progress of computer technology and the existence of \"glitches\" in our reality that could be evidence of the simulation\\'s underlying code.\\nHOST: That\\'s fascinating. Can you tell me more about these \"glitches\" and what they might indicate?\\nGUEST: Well, some people point to phenomena like the \"Mandela effect,\" where large groups of people remember events or facts differently than what\\'s recorded in history books. Others argue that certain unexplained phenomena, like the \"bloop\" sound detected by the National Oceanic and Atmospheric Administration in 1997, could be evidence of the simulators\\' presence or manipulation of our reality.\\nHOST: Let\\'s get started.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('podcast_scripts.json') as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dac3a70-c418-4036-a39b-eca21756bd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kr23w045/25MSGAI/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# speecht5_tts : # https://huggingface.co/microsoft/speecht5_tts\n",
    "\n",
    "# Imports\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b6e7e3-82a8-4986-9740-b69e77691a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TTS models\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "# Load Speaker Embeddings (xvectors)\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "\n",
    "# Define the standard embeddings\n",
    "\n",
    "# Index 0 is 'bdl' (Male)\n",
    "MALE_EMBEDDING = torch.tensor(embeddings_dataset[0][\"xvector\"]).unsqueeze(0)\n",
    "# Index 7306 is 'slt' (Female)\n",
    "FEMALE_EMBEDDING = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe12303-e583-4c39-8154-d0122e39b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved as podcast_1_MALE_MALE.wav\n"
     ]
    }
   ],
   "source": [
    "# Trail podcast script from id:0\n",
    "json_data_entry = d[0]\n",
    "\n",
    "# Extract Data from JSON id:0\n",
    "host_gender = json_data_entry[\"host_gender\"].upper()\n",
    "guest_gender = json_data_entry[\"guest_gender\"].upper()\n",
    "raw_text = json_data_entry[\"dialogue\"]\n",
    "output_filename = f\"podcast_{json_data_entry['id']}_{json_data_entry['host_gender']}_{json_data_entry['guest_gender']}.wav\"\n",
    "\n",
    "# Assign Embeddings based on Gender Data\n",
    "# Assign HOST embedding\n",
    "if host_gender == \"MALE\":\n",
    "    speaker_embeddings_host = MALE_EMBEDDING\n",
    "elif host_gender == \"FEMALE\":\n",
    "    speaker_embeddings_host = FEMALE_EMBEDDING\n",
    "else:\n",
    "    # Default to MALE if gender is not recognized\n",
    "    speaker_embeddings_host = MALE_EMBEDDING\n",
    "    print(f\"Warning: Host gender '{host_gender}' not recognized. Defaulting to Male.\")\n",
    "\n",
    "# Assign GUEST embedding\n",
    "if guest_gender == \"MALE\":\n",
    "    speaker_embeddings_guest = MALE_EMBEDDING\n",
    "elif guest_gender == \"FEMALE\":\n",
    "    speaker_embeddings_guest = FEMALE_EMBEDDING\n",
    "else:\n",
    "    # Default to FEMALE if gender is not recognized\n",
    "    speaker_embeddings_guest = FEMALE_EMBEDDING\n",
    "    print(f\"Warning: Guest gender '{guest_gender}' not recognized. Defaulting to Female.\")\n",
    "\n",
    "# Parse the Dialogue\n",
    "# This regex splits the string while keeping 'HOST:' and 'GUEST:' in the list\n",
    "segments = re.split(r'(HOST:|GUEST:)', raw_text)\n",
    "\n",
    "# Generate Audio Loop\n",
    "all_speech_parts = []\n",
    "current_speaker_embedding = None\n",
    "\n",
    "# Create a 0.3 second silence tensor (16000 sampling rate * 0.3 seconds)\n",
    "silence = torch.zeros(int(16000 * 0.3))\n",
    "\n",
    "for segment in segments:\n",
    "    segment = segment.strip()\n",
    "    \n",
    "    # Determine speaker\n",
    "    if segment == \"HOST:\":\n",
    "        # Assign the dynamically selected HOST embedding\n",
    "        current_speaker_embedding = speaker_embeddings_host\n",
    "        continue\n",
    "    elif segment == \"GUEST:\":\n",
    "        # Assign the dynamically selected GUEST embedding\n",
    "        current_speaker_embedding = speaker_embeddings_guest\n",
    "        continue\n",
    "    \n",
    "    # Skip empty strings or strings that were just keys\n",
    "    if not segment or current_speaker_embedding is None:\n",
    "        continue\n",
    "\n",
    "    # Process text and generate audio\n",
    "    inputs = processor(text=segment, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate speech\n",
    "    speech = model.generate_speech(inputs[\"input_ids\"], current_speaker_embedding, vocoder=vocoder)\n",
    "    \n",
    "    # Add to list\n",
    "    all_speech_parts.append(speech)\n",
    "    all_speech_parts.append(silence) # Add pause after every segment\n",
    "\n",
    "# Concatenate and Save\n",
    "if all_speech_parts:\n",
    "    # Concatenate all tensors into one\n",
    "    final_audio = torch.cat(all_speech_parts, dim=0)\n",
    "    \n",
    "    # Save file with a descriptive name\n",
    "    sf.write(output_filename, final_audio.numpy(), samplerate=16000)\n",
    "    print(f\"Audio saved as {output_filename}\")\n",
    "else:\n",
    "    print(\"No audio generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bd0a4-1d29-4e9d-ac49-a0d9653b7b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
