{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kr23w045/25MSGAI/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio as Audio_rep, display\n",
    "import logging, warnings\n",
    "from transformers import logging as hf_logging\n",
    "from huggingface_hub import login\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset, load_from_disk, Audio\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setting up HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1763453269296,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "tdUdwKrt_TH1"
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Hugging face login\n",
    "#######################################################\n",
    "# Silence transformers/TRL logs early\n",
    "hf_logging.set_verbosity_error()\n",
    "logging.getLogger(\"trl\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hide specific noisy warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\".*loss_type=None.*ForCausalLMLoss.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\".*cuDNN SDPA backward got grad_output\\.strides\\(\\) != output\\.strides\\(\\).*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "os.environ[\"TQDM_NOTEBOOK\"] = \"0\"\n",
    "\n",
    "#############################################\n",
    "########## Google Colab #####################\n",
    "# setting key in secrets google colab\n",
    "# from google.colab import userdata\n",
    "# hf_key = userdata.get('HUGGINGFACE_API_KEY')\n",
    "#############################################\n",
    "########## Locally with env file ############\n",
    "# Load .env file (if present)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "hf_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "#############################################\n",
    "\n",
    "if hf_key:\n",
    "    login(hf_key)\n",
    "else:\n",
    "    raise EnvironmentError(\"HUGGINGFACE_API_KEY not found. Copy .env.template to .env and add your token. See Instruction.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Dataset - LJ Speech Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either download the dataset from Kaggle or Huggingface, 13100 short audio clips, with transcription, from Kaggle \n",
    "you get individual .wav files.\n",
    "\n",
    "The size of the dataset is 3GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mathurinache/the-lj-speech-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.99G/2.99G [02:00<00:00, 26.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /storage/homefs/kr23w045/.cache/kagglehub/datasets/mathurinache/the-lj-speech-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"mathurinache/the-lj-speech-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Create in the root of the project a /datasets folder and move the donwloaded dataset there,\n",
    "# otherwise set use the default path where it has been saved (usually .cache/kagglehub)\n",
    "DATASET_PATH = 'mathurinache/the-lj-speech-dataset/versions/1/LJSpeech-1.1'\n",
    "DATASET_NAME = 'LJSpeech1_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 13100/13100 [00:00<00:00, 87407.19files/s] \n",
      "Generating train split: 13100 examples [00:00, 28601.82 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "df = pd.read_csv(\n",
    "    f\"/storage/homefs/kr23w045/.cache/kagglehub/datasets/mathurinache/the-lj-speech-dataset/versions/1/LJSpeech-1.1/metadata.csv\",\n",
    "    sep=\"|\",\n",
    "    names=[\"id\", \"text\", \"normalized\"],\n",
    ")\n",
    "\n",
    "# Add full audio paths\n",
    "df[\"audio\"] = df[\"id\"].apply(\n",
    "    lambda x: f\"/storage/homefs/kr23w045/.cache/kagglehub/datasets/mathurinache/the-lj-speech-dataset/versions/1/LJSpeech-1.1/wavs{x}.wav\"\n",
    ")\n",
    "\n",
    "# Rename fields to match your benchmark code\n",
    "df = df.rename(columns={\"text\": \"spoken_text\"})\n",
    "\n",
    "# Create HuggingFace dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tell HF that \"audio\" contains audio files\n",
    "dataset = dataset.cast_column(\"audio\", \n",
    "    load_dataset(\"audiofolder\", data_dir=f\"/storage/homefs/kr23w045/.cache/kagglehub/datasets/mathurinache/the-lj-speech-dataset/versions/1/LJSpeech-1.1/wavs\")[\"train\"].features[\"audio\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory datasets/MikhailT/lj-speech not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m dataset_local = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset_local:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     dataset = \u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdatasets\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASET_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      9\u001b[39m     dataset = load_dataset(DATASET_NAME, split=\u001b[33m\"\u001b[39m\u001b[33mfull\u001b[39m\u001b[33m\"\u001b[39m, streaming=\u001b[38;5;28;01mFalse\u001b[39;00m).select(\u001b[38;5;28mrange\u001b[39m(NUM_SAMPLES))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/datasets/load.py:2140\u001b[39m, in \u001b[36mload_from_disk\u001b[39m\u001b[34m(dataset_path, keep_in_memory, storage_options)\u001b[39m\n\u001b[32m   2138\u001b[39m fs, *_ = url_to_fs(dataset_path, **(storage_options \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[32m   2139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fs.exists(dataset_path):\n\u001b[32m-> \u001b[39m\u001b[32m2140\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fs.isfile(posixpath.join(dataset_path, config.DATASET_INFO_FILENAME)) \u001b[38;5;129;01mand\u001b[39;00m fs.isfile(\n\u001b[32m   2142\u001b[39m     posixpath.join(dataset_path, config.DATASET_STATE_JSON_FILENAME)\n\u001b[32m   2143\u001b[39m ):\n\u001b[32m   2144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset.load_from_disk(dataset_path, keep_in_memory=keep_in_memory, storage_options=storage_options)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Directory datasets/MikhailT/lj-speech not found"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"MikhailT/lj-speech\"\n",
    "# load dataset\n",
    "import datasets\n",
    "\n",
    "dataset_local = True\n",
    "if dataset_local:\n",
    "    dataset = load_from_disk(os.path.join('datasets', DATASET_NAME))\n",
    "else:\n",
    "    dataset = load_dataset(DATASET_NAME, split=\"full\", streaming=False).select(range(NUM_SAMPLES))\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", datasets.features.Audio(decode=False))\n",
    "\n",
    "# save dataset locally    \n",
    "# dataset.save_to_disk(f'./datasets/{DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Models Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1763453269344,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "QNvJ_Tm18K5L"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# CONFIGURATION\n",
    "#######################################################\n",
    "from pathlib import Path\n",
    "\n",
    "# Set your models here\n",
    "TTS_MODELS = [\n",
    "    # \"bark_small\", # \"suno/bark-small\",\n",
    "    \"speecht5_tts\", # \"microsoft/speecht5_tts\"                          \n",
    "    \"mms_tts\"\n",
    "]\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Directory to store generated audio\n",
    "OUTPUT_DIR = Path(\"tts_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOREkPHZ3UWt"
   },
   "source": [
    "---\n",
    "### Microsoft/speecht5_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Make sure that the local path to the model is correct.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    469\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/speecht5_tts'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:505\u001b[39m, in \u001b[36mFeatureExtractionMixin.get_feature_extractor_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     resolved_feature_extractor_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_extractor_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:312\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03mTries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:522\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m resolved_files = \u001b[43m[\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfull_filenames\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:523\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m    522\u001b[39m resolved_files = [\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    524\u001b[39m ]\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:140\u001b[39m, in \u001b[36m_get_cache_file_to_return\u001b[39m\u001b[34m(path_or_repo_id, full_filename, cache_dir, revision)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cache_file_to_return\u001b[39m(\n\u001b[32m    137\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m, full_filename: \u001b[38;5;28mstr\u001b[39m, cache_dir: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m ):\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     resolved_file = \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file != _CACHED_NO_EXIST:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/speecht5_tts'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     processor = \u001b[43mSpeechT5Processor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeecht5_tts_local_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspeecht5_tts_local\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/speecht5_tts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     model = SpeechT5ForTextToSpeech.from_pretrained(speecht5_tts_local_path \u001b[38;5;28;01mif\u001b[39;00m speecht5_tts_local \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmicrosoft/speecht5_tts\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/processing_utils.py:1306\u001b[39m, in \u001b[36mProcessorMixin.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[39m\n\u001b[32m   1304\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m] = token\n\u001b[32m-> \u001b[39m\u001b[32m1306\u001b[39m args = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1307\u001b[39m processor_dict, kwargs = \u001b[38;5;28mcls\u001b[39m.get_processor_dict(pretrained_model_name_or_path, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/processing_utils.py:1365\u001b[39m, in \u001b[36mProcessorMixin._get_arguments_from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1363\u001b[39m         attribute_class = \u001b[38;5;28mcls\u001b[39m.get_possibly_dynamic_module(class_name)\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     args.append(\u001b[43mattribute_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:379\u001b[39m, in \u001b[36mFeatureExtractionMixin.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[39m\n\u001b[32m    377\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m] = token\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m feature_extractor_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_feature_extractor_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_dict(feature_extractor_dict, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/25MSGAI/.venv/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:524\u001b[39m, in \u001b[36mFeatureExtractionMixin.get_feature_extractor_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    523\u001b[39m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    525\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt load feature extractor for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. If you were trying to load\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    526\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m it from \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, make sure you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have a local directory with the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m same name. Otherwise, make sure \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is the correct path to a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m directory containing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFEATURE_EXTRACTOR_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m         )\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;66;03m# Load feature_extractor dict\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: Can't load feature extractor for './models/speecht5_tts'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './models/speecht5_tts' is the correct path to a directory containing a preprocessor_config.json file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     vocoder = SpeechT5HifiGan.from_pretrained(os.path.join(speecht5_tts_local_path, \u001b[33m\"\u001b[39m\u001b[33mvocoder\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m speecht5_tts_local \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmicrosoft/speecht5_hifigan\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMake sure that the local path to the model is correct.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     14\u001b[39m     models[\u001b[33m\"\u001b[39m\u001b[33mspeecht5_tts\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33mprocessor\u001b[39m\u001b[33m\"\u001b[39m: processor, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model, \u001b[33m\"\u001b[39m\u001b[33mvocoder\u001b[39m\u001b[33m\"\u001b[39m: vocoder}\n",
      "\u001b[31mOSError\u001b[39m: Make sure that the local path to the model is correct."
     ]
    }
   ],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "\n",
    "speecht5_tts_local_path = './models/speecht5_tts'\n",
    "speecht5_tts_local = True\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    processor = SpeechT5Processor.from_pretrained(speecht5_tts_local_path if speecht5_tts_local else \"microsoft/speecht5_tts\")\n",
    "    model = SpeechT5ForTextToSpeech.from_pretrained(speecht5_tts_local_path if speecht5_tts_local else \"microsoft/speecht5_tts\")\n",
    "    vocoder = SpeechT5HifiGan.from_pretrained(os.path.join(speecht5_tts_local_path, \"vocoder\") if speecht5_tts_local else \"microsoft/speecht5_hifigan\")\n",
    "except OSError:\n",
    "    raise EnvironmentError(\"Make sure that the local path to the model is correct.\")\n",
    "else:\n",
    "    models[\"speecht5_tts\"] = {\"processor\": processor, \"model\": model, \"vocoder\": vocoder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model locally\n",
    "# save_path = \"./models/speecht5_tts\"\n",
    "# models[\"speecht5_tts\"]['model'].save_pretrained(save_path)\n",
    "# models[\"speecht5_tts\"]['processor'].save_pretrained(save_path)\n",
    "# models[\"speecht5_tts\"]['vocoder'].save_pretrained(os.path.join(save_path, 'vocoder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "295f595683e84d34bc3763d31ff87a95",
      "2bb5d1ce96ec44719041f735f597a13c",
      "24660d31fd464d70a511a30bed0d5053",
      "bf998b2be0b44c26a9ec3d14d1e3d177",
      "2a4ba0ec7f6c4d0a8062cdfed5a85622",
      "18c42653e32544a283d73e2099a8b34d",
      "92ee9ed2b9ac4afd9fc79ada0c254c9f",
      "30805482adbf47c3a3fb949f52fe6031",
      "130e20c90e7048eb8519d87bec699de4",
      "01ce262239d54eb288dba669bd54e330",
      "225e293e337a4bb884cd05c3f940584a",
      "ba214e65af624e5680c050181c3d5b98",
      "54f5492abdec48a3a6784afdd35430dd",
      "2d68c40c3a2045eb84e2b6a78a5e7b57",
      "7a27f755e91a49d9a6dfbfc64e54a7ec",
      "4509e690d13f462ebaf7deb263ea1162",
      "f09825a20ae540ec96217b7a5e4e0958",
      "8d5a951ab70c46fdba4cf9b7889c2449",
      "25407e7505c647688e6f3c267c7d2c53",
      "aa0f111e94f3405dba55676472631fc7",
      "b52f92832c034d3390412d529c419b06",
      "9c965f96d84f48ee804e3a6d207fd494",
      "eb4f8657d0074a068f29a944e214eda3",
      "c864deb298f14b279040a0d96b03262c",
      "20f29176438243edb2a6830d37671bef",
      "372d95744609478385b9d2af1dbe7782",
      "cc195d523f9249159d519bb79d0543f4",
      "3f60317574ab489c90a083d20b9a0252",
      "932941e88181402abfc24e6f269ffc93",
      "6bd58e48af50403296304ab9dad8d7da",
      "124975e795e3467d85ba80a65069d57b",
      "46a60099f2c24547aa8f5051d073af86",
      "663e1b727bd54d24808fcd3090b577a9",
      "78000bd8b7eb494ea54038962c99d8dc",
      "7b19108a746942b4ac1530592dff40f9",
      "cae48c01d2cd4ad7958eb512ddad1d0e",
      "da73b8df8368495499ef93560cbdf2a3",
      "9d9e136fe6f14a8b8abf897736940ad5",
      "a7fafbc469604c2ab0710131980f43af",
      "0c4f0abfccea4e65b73fa038291e831c",
      "2c7d4d07089c4cf5808c32e9a7d8d1fe",
      "2b9737d8a3fc47f1abd30b17c50a33cf",
      "c803074d7cde4ff2a819d3a6237b176d",
      "53c4805bcec64bbc8fd3bd981098a9dd",
      "350288b04eac4cb2aba8e005aca59ad0",
      "33a165ddecf14faab7b904ec25bd548e",
      "137ab4d0dff44c489d7435fc6329d10b",
      "997dd796646542e4a4e2f7575ad8f23f",
      "d01b06c5c1604e43973bd161ed68da3d",
      "264c0b0ded2442c8b32dea7fdef52d5f",
      "9a927a7b0e3f4081aa70a4b5199a85fe",
      "be0c3db9697c49edbaebb73ce53cc69e",
      "8915e22fef9445fe90b01fc9c83e0623",
      "4e2b5d2e2e21462f94ad50c4f8cc2b2c",
      "2f34c9ed8822442eb2ac032c6d3408fc",
      "4c25ea0fec4a48b6bc852f9f34805e3b",
      "6f606ac009d847bdbd3b615adf824cca",
      "3c6e40586abf4a378bdb0b92fd84f97c",
      "873dee0cc5054837bccb59afb0ca0996",
      "294410be56ef48b89c590717afd1752f",
      "a8d7df5445c24cc1a70dbcb7c853e062",
      "ea196e49a96444208bbb35163e587f4b",
      "af26b3fe5573478fbca9bf31d2c102f4",
      "e27eeff95e984b10b88e6b4401d01fee",
      "cda6873c816b4a02b5ef2a354730ce82",
      "3ec48efe8710456b95f61ed2a449bc74",
      "523254a696ed455793ea137f722e0b2b",
      "ce64743517c24372896bda307df067c4",
      "2902d81f43674e67a363e99e7c9a4b9a",
      "5922e077f65b47cdb7cb3c581cef6990",
      "23cd8a8a762849b18a2da1bb295f6a87",
      "305afd41d81b415ab69c9895655f0de7",
      "a906bc7bbeff4a53b24067c120269dc0",
      "d0ff229f3b61456cb82f94317ae49ea8",
      "492895dafe0243b4b38060a4e5f3a057",
      "fe1eb1fd2dc340aea64625849611320b",
      "1f0206adb7374f4d9efb6bc1ffb56185",
      "6671e81283794420b2d9e97f719c5c7e",
      "69ed15a9b4c9466b87535d54c45bcf03",
      "028bdb54db4c426d9fd3e67600d39bea",
      "a9abface27ad412bbad4654dbc66963c",
      "1a2373ef58f04b4ea15465bb686cc706",
      "f5d08be1c20c49b2ab98afb14a2d2dc9",
      "2727528989b743108ca2505fd708d8fa",
      "7f0a98fae56741b6896fbe2b414f9548",
      "2507e3d1bcb24770b731151f39a2aa30",
      "d96df5231e5f4734a1240a57c4fe2574",
      "c656acf25e2c40cd862b40f7408dfc36",
      "a1881bbed3a24252a73dbc540563c366",
      "d418e58d1b1d48b8a60a179d6c2675d9",
      "04d0231dedf34b639ee6ba68833819dd",
      "d243bb0dc6fa4a469ffd664b7c3166f1",
      "0049942822804802ae0758ab039d5dfb",
      "fc9f781429784c4191a8330cde3b13d6",
      "2e3f67d8e81e41a6bee1f33965de7e71",
      "f296225bffe74f609fa2da6e2eb9c8ef",
      "64eb9093f7464a8b8962055589202a72",
      "9de1664387d04472a44c2ec359ee6ad2",
      "69eee7e6b4ce4dfd8a5835c3e4272a82",
      "8d27ffa7571f416e998921517cd9ed24",
      "dcb47c7337a0412b91b55aaf553c28de",
      "e7b6be45050d46f3beba7fdad78418ee",
      "8da524ab48614c08a1f45ff0fa981bab",
      "c00421509a444d3aa438b9258314ec38",
      "c85428bbea6f4cd99bf8d4d6d3fabfc0",
      "27bd50808866461aa5ed4da2197ebf0b",
      "0d46dffc12514bae92dd992ca26f99d3",
      "bcb7338c17ba43dc9d1b5531f40411c9",
      "7d1dc0e7e7f54b89af00da117dd42bb0",
      "13bfcf8074f045b6ac4e9e55ca155fe6",
      "15fabcf9607d4a0dbe62322db6e2a68d",
      "a7337f6435be407c895b3720219781aa",
      "497bc9eb9d7042e8832885d072c0c358",
      "87a876686a954ab883c11c9755543d6e",
      "180a02582db74d06b9ff27c4cf191de0",
      "4a01b6e92bdb40b7a37f5c388f77d7b7",
      "258a417c8fb74e819ce1102cc57c0b55",
      "777dbd3efdde4c4488058ad0e526afe4",
      "599b23c960e641c5b0d111b93762e8fe",
      "db39125877e4464384ca9f49b6053a68",
      "51d299e9ec1840e9bb2e6d7055bff1ac"
     ]
    },
    "executionInfo": {
     "elapsed": 17366,
     "status": "ok",
     "timestamp": 1763453605608,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "PfZg5aq23cZw",
    "outputId": "dd36c897-c019-4e1c-ed01-69cebf1e6fae"
   },
   "outputs": [],
   "source": [
    "# Prepare input text\n",
    "inputs = models['speecht5_tts']['processor'](text=\"Test one, two, three, I am talking!\", return_tensors=\"pt\")\n",
    "\n",
    "# Use a random speaker embedding (512 dimensions)\n",
    "speaker_embeddings = torch.randn(1, 512)\n",
    "\n",
    "# Generate speech\n",
    "with torch.no_grad():\n",
    "    speech = models['speecht5_tts']['model'].generate_speech(\n",
    "        inputs[\"input_ids\"],\n",
    "        speaker_embeddings,\n",
    "        vocoder=models['speecht5_tts']['vocoder']\n",
    "    )\n",
    "\n",
    "# Save output\n",
    "sf.write(f\"{OUTPUT_DIR}/speecht5_tts/speech_test.wav\", speech.numpy(), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1763453656286,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "dqDlJAG14PcF",
    "outputId": "a2871380-5a6d-4d3e-c720-ef1d587d00c3"
   },
   "outputs": [],
   "source": [
    "display(Audio_rep(f\"{OUTPUT_DIR}/speecht5_tts/speech_test.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### facebook/mms-tts-eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VitsModel, AutoTokenizer\n",
    "\n",
    "mms_tts_local_path = './models/mms_tts'\n",
    "mms_tts_local = False\n",
    "# Load models\n",
    "try:\n",
    "    model = VitsModel.from_pretrained(mms_tts_local_path if mms_tts_local else \"facebook/mms-tts-eng\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(mms_tts_local_path if mms_tts_local else \"facebook/mms-tts-eng\")\n",
    "except OSError:\n",
    "    raise EnvironmentError(\"Make sure that the local path to the model is correct.\")\n",
    "else:\n",
    "    models[\"mms_tts\"] = {\"model\": model, \"tokenizer\": tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model locally\n",
    "# save_path = \"./models/mms_tts\"\n",
    "# models[\"mms_tts\"]['model'].save_pretrained(save_path)\n",
    "# models[\"mms_tts\"]['tokenizer'].save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Test one, two, three, I am talking!\"\n",
    "inputs = models['mms_tts']['tokenizer'](text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = models['mms_tts']['model'](**inputs).waveform\n",
    "\n",
    "sf.write(f\"{OUTPUT_DIR}/mms_tts/speech_test.wav\", output.cpu().numpy().squeeze(), models['mms_tts']['model'].config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio_rep(f\"{OUTPUT_DIR}/mms_tts/speech_test.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1763453921423,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "kPHhfnxg_f5b"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# METRICS — Small, simple (expand as needed)\n",
    "#######################################################\n",
    "import soundfile as sf\n",
    "\n",
    "def audio_duration(path):\n",
    "    \"\"\"Returns duration in seconds.\"\"\"\n",
    "    y, sr = librosa.load(path, sr=None)\n",
    "    return len(y) / sr\n",
    "\n",
    "def infer_model(models, model_name, texts):\n",
    "    if model_name == 'speecht5_tts':\n",
    "        if len(texts) > 1:\n",
    "            print(\"Speecht5_tts cannot be ran with batches, only the first text will be passed to the model\")\n",
    "            \n",
    "        inputs = models[model_name]['processor'](text=texts[0], return_tensors=\"pt\")\n",
    "        # Use a random speaker embedding (512 dimensions)\n",
    "        # speaker_embeddings = torch.randn(1, 512)\n",
    "        # fix voice for the moment\n",
    "        speaker_embeddings = torch.zeros(1, 512)\n",
    "\n",
    "        # Generate speech\n",
    "        with torch.no_grad():\n",
    "            generated = models[model_name]['model'].generate_speech(\n",
    "                inputs[\"input_ids\"],\n",
    "                speaker_embeddings,\n",
    "                vocoder=models[model_name]['vocoder']\n",
    "            )\n",
    "        \n",
    "        return [generated]\n",
    "        \n",
    "    elif model_name == 'mms_tts':\n",
    "        inputs = models[model_name]['tokenizer'](text=texts, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "          generated = models[model_name]['model'](**inputs).waveform\n",
    "        \n",
    "        return generated\n",
    "\n",
    "    else:\n",
    "        Warning(\"Model not implemented yet!\")\n",
    "        return None\n",
    "\n",
    "def save_gen_audio(model_name, output_audio_path, audio, sample):\n",
    "    if model_name == 'speecht5_tts':\n",
    "        # output_audio_path = model_dir / f\"sample_{b_start}_bs{batch_size}.wav\"\n",
    "        sf.write(output_audio_path, audio.numpy(), 16000)\n",
    "        # Metrics\n",
    "        duration = audio_duration(output_audio_path)\n",
    "        # similarity = mel_spectrogram_similarity(reference_audio_path,output_audio_path)\n",
    "    elif model_name == 'mms_tts':\n",
    "        waveform = audio.cpu().numpy()\n",
    "        sf.write(output_audio_path, waveform, models[model_name]['model'].config.sampling_rate)\n",
    "        # Metrics\n",
    "        duration = audio_duration(output_audio_path)\n",
    "        # similarity = mel_spectrogram_similarity(reference_audio_path,output_audio_path)\n",
    "\n",
    "    return {\n",
    "        \"text\": sample[\"spoken_text\"],\n",
    "        \"reference\": sample[\"audio\"][\"path\"],\n",
    "        \"generated\": str(output_audio_path),\n",
    "        \"duration\": duration\n",
    "        # \"mel_similarity\": float(similarity)\n",
    "    }\n",
    "\n",
    "# def mel_spectrogram_similarity(ref_path, gen_path):\n",
    "#     \"\"\"\n",
    "#     Simple similarity metric comparing mel spectrogram cosine similarity.\n",
    "#     Not perfect, but useful for midterm presentation.\n",
    "#     \"\"\"\n",
    "#     ref, sr_ref = librosa.load(ref_path, sr=22050)\n",
    "#     gen, sr_gen = librosa.load(gen_path, sr=22050)\n",
    "\n",
    "#     ref_mel = librosa.feature.melspectrogram(ref, sr=22050)\n",
    "#     gen_mel = librosa.feature.melspectrogram(gen, sr=22050)\n",
    "\n",
    "#     ref_vec = np.mean(ref_mel, axis=1)\n",
    "#     gen_vec = np.mean(gen_mel, axis=1)\n",
    "\n",
    "#     return 1 - cosine(ref_vec, gen_vec)\n",
    "    \n",
    "\n",
    "#######################################################\n",
    "# Run the benchmark on a given dataset\n",
    "#######################################################\n",
    "def run_tts_benchmark(dataset, exp_folder):\n",
    "\n",
    "    for model_name in TTS_MODELS:\n",
    "        print(f\"\\n### Running inference for: {model_name}\")\n",
    "        model_dir = OUTPUT_DIR / model_name.replace(\"/\", \"_\") / exp_folder\n",
    "        model_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Warmup the model\n",
    "        warmup_text = \"Warm up the model.\"\n",
    "        print(\"Running warm-up…\")\n",
    "        _ = infer_model(models, model_name, [warmup_text])\n",
    "        print(\"Warm-up complete.\\n\")\n",
    "        \n",
    "        for batch_size in BATCH_SIZES:\n",
    "          print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "          model_results = []\n",
    "          samples = list(dataset)\n",
    "\n",
    "          if (model_name == 'speecht5_tts' and batch_size != 1):\n",
    "             print('speecht5_tts does not support batching, skip...')\n",
    "             continue\n",
    "\n",
    "          for b_start in tqdm(range(0, len(samples), batch_size)):\n",
    "              batch = samples[b_start:b_start+batch_size]\n",
    "              texts = [s[\"spoken_text\"] for s in batch]\n",
    "\n",
    "              # ----- Inference -----\n",
    "              t0 = time.time()\n",
    "\n",
    "              generated_batch = infer_model(models, model_name, texts)\n",
    "\n",
    "              if generated_batch is None:\n",
    "                  print(\"Something went wrong while generating the batch!\")\n",
    "                  return\n",
    "\n",
    "              t1 = time.time()\n",
    "\n",
    "              ## save generated audio and results\n",
    "              for idx, (sample, audio) in enumerate(zip(batch, generated_batch)):\n",
    "                output_audio_path = model_dir / f\"sample_{b_start + idx}_bs{batch_size}.wav\"\n",
    "                results = save_gen_audio(model_name, output_audio_path, audio, sample)\n",
    "                results['batch_size'] = batch_size\n",
    "                results['inference_time'] = t1 - t0\n",
    "                model_results.append(results)\n",
    "\n",
    "          # Save model results\n",
    "          with open(model_dir / f\"results_bs{batch_size}.json\", \"w\") as f:\n",
    "              json.dump(model_results, f, indent=2)\n",
    "              \n",
    "    print(\"\\nDone! Benchmarking done, save results in\", OUTPUT_DIR, \" and inside the model folder, under \", exp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [1, 5]\n",
    "NUM_SAMPLES = 2   # subset for fast evaluation\n",
    "exp_folder = 'test0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1tux8_EjCyn4hv5bt7zQEZJALDrhvCERA"
    },
    "executionInfo": {
     "elapsed": 261255,
     "status": "ok",
     "timestamp": 1763454183530,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "hFcTgUMH8zZx",
    "outputId": "4a1fbe4e-9d63-40f9-cb42-90d4c3ab2ef0"
   },
   "outputs": [],
   "source": [
    "dataset_sampled = dataset.select(range(NUM_SAMPLES))\n",
    "run_tts_benchmark(dataset_sampled, exp_folder)\n",
    "print(TTS_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763454441239,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "3DCxkJ18AyYr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exp_to_import = 'test0'\n",
    "df_mms_tts_b1 = pd.read_json(f'tts_results/mms_tts/{exp_to_import}/results_bs1.json')\n",
    "df_mms_tts_b5 = pd.read_json(f'tts_results/mms_tts/{exp_to_import}/results_bs5.json')\n",
    "df_speecht5_tts_b1 = pd.read_json(f'tts_results/speecht5_tts/{exp_to_import}/results_bs1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1763454463286,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "qXX-MnuKE4Ir",
    "outputId": "8f5737a9-14b7-44a1-a5be-4a621f273181"
   },
   "outputs": [],
   "source": [
    "df_mms_tts_b1.head(5)\n",
    "df_mms_tts_b1['rtf'] = df_mms_tts_b1['duration']/df_mms_tts_b1['inference_time']\n",
    "df_mms_tts_b1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mms_tts_b5.head(5)\n",
    "df_mms_tts_b5['rtf'] = 5*df_mms_tts_b5['duration']/df_mms_tts_b5['inference_time']\n",
    "df_mms_tts_b5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speecht5_tts_b1.head(5)\n",
    "df_speecht5_tts_b1['rtf'] = df_speecht5_tts_b1['duration']/df_speecht5_tts_b1['inference_time']\n",
    "df_speecht5_tts_b1.describe()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMIP/Y1hL+PXS5z+9n/PgnW",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
