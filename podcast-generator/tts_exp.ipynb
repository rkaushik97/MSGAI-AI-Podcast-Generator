{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16910,
     "status": "ok",
     "timestamp": 1765531367400,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "bL4mzWy_tE_F",
    "outputId": "dc454131-bcf1-46fc-ad89-107ae7a9c84f"
   },
   "outputs": [],
   "source": [
    "# branch_name = \"main\"\n",
    "# repo_url = \"https://github.com/rkaushik97/MSGAI-AI-Podcast-Generator.git\"\n",
    "\n",
    "# !git clone -b {branch_name} --single-branch {repo_url}\n",
    "\n",
    "# from google.colab import userdata\n",
    "# # setting key in secrets google colab\n",
    "# hf_token = userdata.get('HUGGINGFACE_API_KEY')\n",
    "\n",
    "# !pip install kokoro_onnx piper-tts jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765531367425,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "XuCNS-MbtSUY",
    "outputId": "75825a77-b047-4ac2-800e-7f2199d3290d"
   },
   "outputs": [],
   "source": [
    "# after having created in msgai folder the kokoro folder with the .bin and .onnx files\n",
    "# for the model, you can find them in the readme.md\n",
    "# %cd MSGAI-AI-Podcast-Generator/podcast-generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rww5dv9Ju20A"
   },
   "source": [
    "## Load the results of the experiment on the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765531367439,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "GEzkBFEnu6zZ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# import pandas as pd\n",
    "\n",
    "# with open('../notebooks/llm_exp/full_exp_merged.json') as infile:\n",
    "#   results = json.load(infile)\n",
    "with open('../notebooks/llm_exp/full_exp_merged.json') as infile:\n",
    "  llm_results = json.load(infile)\n",
    "\n",
    "# llm_results = pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1765531367463,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "Cvn7lAcgu9LD",
    "outputId": "787f5319-0d41-42cc-cc92-a43e196f8b97"
   },
   "outputs": [],
   "source": [
    "llm_results[0].keys()\n",
    "llm_results[0]['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "br_5vheOvDCe"
   },
   "source": [
    "## Pass the generated script of the podcast to the TTS and evaluate WER and Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f3874660cff1410390a637cc015831b5",
      "4a0cd35e5d1d4702b9b7e46ba050f436",
      "c71dec352b3c40b5a6fe6897f768b3b5",
      "179ded8b0a284997b3b3915b7be613c0",
      "d17ed72e7836443194176b81612bfc11",
      "8b80745bdc8f4b1dafa16508af43bc0f",
      "49117db7cf6d4fd1ae7386b981cc37bd",
      "f79d48e86742446387607af786daa533",
      "af085544d65241758f22daaf762e606f",
      "044371df9dde441d9e0d399e8e5bed3e",
      "997135ea61334b67a6f624745d662397",
      "bdeba8310b1d414db648ef5d9b1fa387",
      "53dcb36ecedf47e08c9db08162a0b257",
      "dd17b7f97d0c40789bd985592c707c56",
      "0e252a516d4141278ad3b6688123dea7",
      "817cdb387b6c4a21b0bbaa9fea44e6a2",
      "a2cd09e3eb7d4e72b5a9198b7aa60ab8",
      "ff823985b4c2430587e7c0ebdb9b27bd",
      "ad30febda42a4c72800cb11eb9734cdb",
      "2c33f5a41ae1492abd2d1612b8158a89",
      "560910ff7f994ee2ad9c5a0c835d942a",
      "1686d7fd8ba6430eafa71120d25d63de",
      "91f57e476758442caed61ef9ad56e072",
      "b3d505ea903b41b782d6731c6940bd45",
      "1af65fa891eb4316a79019cec4688454",
      "0c6abb73366e40c995762d6401398de4",
      "b76213971342456daffd42ad121e3ddb",
      "62fc1858c74b46288b505fab505857d7",
      "7cae5dd064d246c49c8a9f918737e242",
      "dca0e311be82431abfb886caf5c18a53",
      "3688fa3194ae4161875a24acc9e9c975",
      "ce76d0519e024381bcd5cdb41f29f596",
      "c1560bb495a14748a93e955863069438",
      "9c8f1cdf93534599a79ff41f6b2976f9",
      "9f91180e68b64a3aaedb4a600d331661",
      "a523544bdf1f4c1ea7827655e4f06682",
      "00c35db3e6734680a8d75a334b07a58c",
      "340944a2d205443eac68eac6468e3af1",
      "1cc7683e87d3446299ab49981a581211",
      "1fc921f8a2664172b49de765e87bf9dd",
      "321bddff71264dc496cd8fbe40884962",
      "80008e46902d4ac1b386cf199d9d118f",
      "e1d57bba5ea5447a81bcf3fdabf5e21d",
      "8351f127104743a3b197f020849b0d1f"
     ]
    },
    "executionInfo": {
     "elapsed": 53207,
     "status": "error",
     "timestamp": 1765531782167,
     "user": {
      "displayName": "Sebastian Käslin",
      "userId": "02952943538578971170"
     },
     "user_tz": -60
    },
    "id": "0EGuKjVtvJx7",
    "outputId": "be8d16cd-e2ae-48bd-81e8-be3601daf7b0"
   },
   "outputs": [],
   "source": [
    "from podcast_pipeline.adaptive_tts_synthesizer import AdaptiveTTSSynthesizer\n",
    "from podcast_pipeline.audio_quality_analyzer import AudioQualityAnalyzer\n",
    "import os\n",
    "\n",
    "# tts_backend = 'kokoro'\n",
    "tts_backend = 'piper'\n",
    "\n",
    "output_filename_full = f'output/experiment/test_{tts_backend}.wav'\n",
    "script_filename_full = f'output/experiment/test_{tts_backend}.md'\n",
    "\n",
    "# with open(script_filename_full, 'w', encoding='utf-8') as f:\n",
    "#             f.write(f\"# Podcast Script: {llm_results[0]['output_text']['topic']}\\n\\n\")\n",
    "#             f.write(f\"Metadata: Host={llm_results[0]['output_text']['metadata']['HOST_GENDER']}, Guest={llm_results[0]['output_text']['metadata']['GUEST_GENDER']}\\n\\n\")\n",
    "#             f.write(\"--- Dialogue ---\\n\\n\")\n",
    "#             f.write(llm_results[0]['output_text']['dialogue'])\n",
    "\n",
    "adaptive_tts = AdaptiveTTSSynthesizer(tts_backend)\n",
    "\n",
    "adaptive_tts.synthesize(llm_results[0]['output_text'], output_filename_full)\n",
    "\n",
    "analyzer = AudioQualityAnalyzer()\n",
    "\n",
    "audio_quality_results = analyzer.evaluate(audio_path=output_filename_full,\n",
    "                    transcript_md_path=None,\n",
    "                    script=llm_results[0]['output_text']\n",
    "                    )\n",
    "\n",
    "audio_quality_scores = {\n",
    "    \"wer\": audio_quality_results[\"wer\"],\n",
    "    \"detailed_measures\": audio_quality_results[\"detailed_measures\"],\n",
    "    \"audio_metrics\": audio_quality_results[\"audio_metrics\"]\n",
    "}\n",
    "\n",
    "# Save audio quality report\n",
    "audio_quality_report = f\"test_audio_quality.json\"\n",
    "analyzer.save_results(audio_quality_results, os.path.join(\"output/experiment\", audio_quality_report))\n",
    "\n",
    "# Print summary\n",
    "analyzer.print_summary(audio_quality_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_quality_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UO6KcfTcxCKP"
   },
   "outputs": [],
   "source": [
    "from podcast_pipeline.adaptive_tts_synthesizer import AdaptiveTTSSynthesizer\n",
    "from podcast_pipeline.audio_quality_analyzer import AudioQualityAnalyzer\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tts_backend = 'kokoro'\n",
    "tts_backend = 'piper'\n",
    "\n",
    "audio_quality_scores_tot = []\n",
    "adaptive_tts = AdaptiveTTSSynthesizer(tts_backend)\n",
    "\n",
    "for i, result in tqdm(enumerate(llm_results[:10])):\n",
    "  output_filename_full = f'output/experiment/gen_{i}_{tts_backend}.wav'\n",
    "  script_filename_full = f'output/experiment/gen_{i}_{tts_backend}.md'\n",
    "\n",
    "  # with open(script_filename_full, 'w', encoding='utf-8') as f:\n",
    "  #             f.write(f\"# Podcast Script: {result['output_text']['topic']}\\n\\n\")\n",
    "  #             f.write(f\"Metadata: Host={result['output_text']['metadata']['HOST_GENDER']}, Guest={results[0]['output_text']['metadata']['GUEST_GENDER']}\\n\\n\")\n",
    "  #             f.write(\"--- Dialogue ---\\n\\n\")\n",
    "  #             f.write(result['output_text']['dialogue'])\n",
    "  \n",
    "  adaptive_tts.synthesize(result['output_text'], output_filename_full)\n",
    "\n",
    "  analyzer = AudioQualityAnalyzer()\n",
    "\n",
    "  audio_quality_results = analyzer.evaluate(audio_path=output_filename_full,\n",
    "                      transcript_md_path=None,\n",
    "                      script=result['output_text']\n",
    "                      )\n",
    "\n",
    "  audio_quality_scores = {\n",
    "      \"wer\": audio_quality_results[\"wer\"],\n",
    "      \"detailed_measures\": audio_quality_results[\"detailed_measures\"],\n",
    "      \"audio_metrics\": audio_quality_results[\"audio_metrics\"]\n",
    "  }\n",
    "\n",
    "  audio_quality_scores_tot.append(audio_quality_scores)\n",
    "\n",
    "  # Save audio quality report\n",
    "  audio_quality_report = f\"gen_{i}_{tts_backend}.json\"\n",
    "  analyzer.save_results(audio_quality_results, os.path.join(\"output/experiment\", audio_quality_report))\n",
    "\n",
    "  # Print summary\n",
    "  analyzer.print_summary(audio_quality_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMijDJHxZ51B+eaaw44w8bh",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "msgai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
